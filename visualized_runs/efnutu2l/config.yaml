wandb_version: 1

_wandb:
  desc: null
  value:
    cli_version: 0.12.21
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    m:
    - 1: step
      6:
      - 3
    - 1: epoch
      6:
      - 3
    - 1: training/accuracy
      5: 1
      6:
      - 1
      - 3
    - 1: training/loss
      5: 1
      6:
      - 1
      - 3
    - 1: validation/accuracy
      5: 2
      6:
      - 1
      - 3
    - 1: validation/loss
      5: 2
      6:
      - 1
      - 3
    - 1: grokking/epoch_train>95%
      6:
      - 3
    - 1: grokking/epoch_val>95%
      6:
      - 3
    - 1: grokking/epoch_delay
      6:
      - 3
    - 1: grokking/step_train>95%
      6:
      - 3
    - 1: grokking/step_val>95%
      6:
      - 3
    - 1: grokking/step_delay
      6:
      - 3
    - 1: grad_norm/token_embeddings/weight
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/position_embeddings/weight
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/0/self_attn/in_proj_weight
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/0/self_attn/in_proj_bias
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/0/self_attn/out_proj/weight
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/0/self_attn/out_proj/bias
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/0/self_attn_norm/weight
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/0/self_attn_norm/bias
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/0/ffn/0/weight
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/0/ffn/0/bias
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/0/ffn/2/weight
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/0/ffn/2/bias
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/0/ffn_norm/weight
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/0/ffn_norm/bias
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/1/self_attn/in_proj_weight
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/1/self_attn/in_proj_bias
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/1/self_attn/out_proj/weight
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/1/self_attn/out_proj/bias
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/1/self_attn_norm/weight
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/1/self_attn_norm/bias
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/1/ffn/0/weight
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/1/ffn/0/bias
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/1/ffn/2/weight
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/1/ffn/2/bias
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/1/ffn_norm/weight
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/1/ffn_norm/bias
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/2/weight
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/2/bias
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/3/weight
      5: 1
      6:
      - 1
      - 3
    - 1: grad_norm/model/3/bias
      5: 1
      6:
      - 1
      - 3
    python_version: 3.10.11
    start_time: 1713903668
    t:
      1:
      - 1
      - 55
      2:
      - 1
      - 55
      3:
      - 2
      - 3
      - 7
      - 16
      4: 3.10.11
      5: 0.12.21
      8:
      - 5
batch_size:
  desc: null
  value: 512
device:
  desc: null
  value: cuda
dim_model:
  desc: null
  value: 128
learning_rate:
  desc: null
  value: 0.01
noise_level:
  desc: null
  value: 0.1
num_heads:
  desc: null
  value: 4
num_layers:
  desc: null
  value: 2
num_steps:
  desc: null
  value: 100000
operation:
  desc: null
  value: x/y
prime:
  desc: null
  value: 97
scale_factor:
  desc: null
  value: 100
training_fraction:
  desc: null
  value: 0.3
weight_decay:
  desc: null
  value: 1
